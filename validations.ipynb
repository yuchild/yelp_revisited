{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32d6ec07-e16a-4602-8341-8712315395a8",
   "metadata": {},
   "source": [
    "### Yelp Dataset 10Mar2025 Validations or Proof of Concepts\n",
    "#### 1. Extrat Tar File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1590e9a-f422-4371-84f2-d796295769f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3269aa26-1ee4-4d0a-a49f-5e92be4f78cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import modules as f\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9683b848-2caf-4aac-82a2-43c17afa1d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Mapping: state abbreviation to full name\n",
    "us_state_abbrev_to_name = {\n",
    "    'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas',\n",
    "    'CA': 'California', 'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware',\n",
    "    'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho',\n",
    "    'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas',\n",
    "    'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',\n",
    "    'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi',\n",
    "    'MO': 'Missouri', 'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada',\n",
    "    'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico', 'NY': 'New York',\n",
    "    'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah',\n",
    "    'VT': 'Vermont', 'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia',\n",
    "    'WI': 'Wisconsin', 'WY': 'Wyoming', 'DC': 'District of Columbia'\n",
    "}\n",
    "\n",
    "# Load business data\n",
    "business_df = pd.read_parquet(\"./data/business.parquet\")\n",
    "state_counts = business_df.groupby(\"state\").size().reset_index(name=\"business_count\")\n",
    "state_counts[\"state\"] = state_counts[\"state\"].str.upper()\n",
    "state_counts[\"state_name\"] = state_counts[\"state\"].map(us_state_abbrev_to_name)\n",
    "\n",
    "# Load GeoJSON\n",
    "us_states_url = \"https://eric.clst.org/assets/wiki/uploads/Stuff/gz_2010_us_040_00_500k.json\"\n",
    "us_states = gpd.read_file(us_states_url)\n",
    "\n",
    "# Merge using full state names\n",
    "merged = us_states.merge(state_counts, left_on=\"NAME\", right_on=\"state_name\", how=\"left\")\n",
    "merged[\"business_count\"] = merged[\"business_count\"].fillna(0).astype(int)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "merged.plot(\n",
    "    column=\"business_count\",\n",
    "    ax=ax,\n",
    "    legend=True,\n",
    "    cmap=\"OrRd\",\n",
    "    edgecolor=\"black\",\n",
    "    legend_kwds={'label': \"Number of Yelp Businesses\", 'shrink': 0.5}\n",
    ")\n",
    "ax.set_title(\"Yelp Business Count by State\", fontsize=16)\n",
    "ax.set_xlim([-180, -60])  # include AK\n",
    "ax.set_ylim([15, 75])     # include HI\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635e1c88-7798-4422-a2f5-e9620faf30c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sample Yelp states:\", state_counts['state'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376aba16-e71b-4e89-8132-5f7f77074e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business Summary Table\n",
    "\n",
    "# Load all necessary data\n",
    "review_df = pd.read_parquet(\"./data/review.parquet\")\n",
    "checkin_df = pd.read_parquet(\"./data/checkin.parquet\")\n",
    "tip_df = pd.read_parquet(\"./data/tip.parquet\")\n",
    "photo_df = pd.read_parquet(\"./data/photo.parquet\")\n",
    "\n",
    "# --- Aggregations ---\n",
    "# Unique users per business (from review and tip)\n",
    "users_from_reviews = review_df.groupby(\"business_id\")[\"user_id\"].nunique()\n",
    "users_from_tips = tip_df.groupby(\"business_id\")[\"user_id\"].nunique()\n",
    "\n",
    "# Combine both sources of users\n",
    "total_users = users_from_reviews.add(users_from_tips, fill_value=0).astype(int)\n",
    "\n",
    "# Total reviews\n",
    "total_reviews = review_df.groupby(\"business_id\").size()\n",
    "\n",
    "# Total checkins (count timestamps)\n",
    "checkin_df[\"checkin_count\"] = checkin_df[\"date\"].str.split(\",\").apply(len)\n",
    "total_checkins = checkin_df.groupby(\"business_id\")[\"checkin_count\"].sum()\n",
    "\n",
    "# Total tips\n",
    "total_tips = tip_df.groupby(\"business_id\").size()\n",
    "\n",
    "# Total photos\n",
    "total_photos = photo_df.groupby(\"business_id\").size()\n",
    "\n",
    "# --- Combine all metrics ---\n",
    "agg_df = pd.DataFrame({\n",
    "    \"total_users\": total_users,\n",
    "    \"total_reviews\": total_reviews,\n",
    "    \"total_checkins\": total_checkins,\n",
    "    \"total_tips\": total_tips,\n",
    "    \"total_photos\": total_photos\n",
    "}).fillna(0).astype(int)\n",
    "\n",
    "agg_df.reset_index(inplace=True)  # make business_id a column\n",
    "\n",
    "# Display\n",
    "from IPython.display import display\n",
    "display(agg_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52de0a76-7ab5-41ff-a7cf-b32223d98f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(agg_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3e9935-e59f-4c6b-a260-d5de8f0e9005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User summary table\n",
    "# --- total_reviews & total_businesses_visited ---\n",
    "review_stats = review_df.groupby(\"user_id\").agg(\n",
    "    total_reviews=(\"review_id\", \"count\"),\n",
    "    total_businesses_visited=(\"business_id\", \"nunique\")\n",
    ")\n",
    "\n",
    "# --- total_checkins ---\n",
    "# Count check-ins per business\n",
    "checkin_expanded = checkin_df.copy()\n",
    "checkin_expanded[\"checkin_count\"] = checkin_expanded[\"date\"].str.split(\",\").apply(len)\n",
    "\n",
    "# Join with review_df to associate users to check-ins via business_id\n",
    "checkin_with_users = checkin_expanded.merge(\n",
    "    review_df[[\"user_id\", \"business_id\"]],\n",
    "    on=\"business_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Sum check-ins by user\n",
    "user_checkins = checkin_with_users.groupby(\"user_id\")[\"checkin_count\"].sum()\n",
    "\n",
    "# --- total_tips_written ---\n",
    "user_tips = tip_df.groupby(\"user_id\").size().rename(\"total_tips_written\")\n",
    "\n",
    "# --- Merge all ---\n",
    "user_summary = review_stats.copy()\n",
    "user_summary[\"total_checkins\"] = user_checkins\n",
    "user_summary[\"total_tips_written\"] = user_tips\n",
    "\n",
    "# Final cleanup\n",
    "user_summary = user_summary.fillna(0).astype(int).reset_index()\n",
    "\n",
    "# Display\n",
    "from IPython.display import display\n",
    "display(user_summary.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99723c92-b48d-4f91-9eca-75441cca560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(user_summary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d241b3-a52f-42a1-9594-c8510b04d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "mem = psutil.virtual_memory()\n",
    "print(f\"Used: {mem.used / 1e9:.2f} GB / Total: {mem.total / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744a5e91-d10a-4822-8aa5-a68585c8718d",
   "metadata": {},
   "source": [
    "### Recommender Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c9bbc1-b813-4312-a11c-093ed8279150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Suppress convergence warnings from NMF\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# Load business + review data\n",
    "business_df = pd.read_parquet(\"./data/business.parquet\")\n",
    "review_df = pd.read_parquet(\"./data/review.parquet\")\n",
    "\n",
    "# Filter California businesses with business_id and name\n",
    "ca_businesses = business_df[business_df[\"state\"] == \"CA\"][[\"business_id\", \"name\"]]\n",
    "\n",
    "# Join business name into reviews\n",
    "ca_reviews = review_df.merge(ca_businesses, on=\"business_id\")\n",
    "\n",
    "# Create pivot table: rows = user_id, columns = business_id, values = count of reviews\n",
    "pivot_df = ca_reviews.pivot_table(\n",
    "    index=\"user_id\",\n",
    "    columns=\"business_id\",\n",
    "    values=\"review_id\",\n",
    "    aggfunc=\"count\",\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Train NMF model\n",
    "nmf_model = NMF(n_components=11, init='random', random_state=42, max_iter=500,) # increase from 200\n",
    "user_features = nmf_model.fit_transform(pivot_df)\n",
    "business_features = nmf_model.components_\n",
    "\n",
    "# Save for recommendation\n",
    "user_index = pivot_df.index\n",
    "business_columns = pivot_df.columns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For fast lookup of names\n",
    "business_id_to_name = ca_businesses.set_index(\"business_id\")[\"name\"].to_dict()\n",
    "\n",
    "def recommend_top_5(user_id: str):\n",
    "    if user_id not in pivot_df.index:\n",
    "        return f\"User {user_id} not found in California data.\"\n",
    "\n",
    "    user_idx = list(pivot_df.index).index(user_id)\n",
    "    user_vector = user_features[user_idx]\n",
    "\n",
    "    # Predict all business scores\n",
    "    user_pred = np.dot(user_vector, business_features)\n",
    "\n",
    "    # Get already reviewed businesses\n",
    "    reviewed = pivot_df.loc[user_id]\n",
    "    reviewed_businesses = reviewed[reviewed > 0].index\n",
    "\n",
    "    # Filter out businesses the user already reviewed\n",
    "    recommendations = [\n",
    "        (biz_id, score) for biz_id, score in zip(business_columns, user_pred)\n",
    "        if biz_id not in reviewed_businesses\n",
    "    ]\n",
    "\n",
    "    # Sort by predicted score\n",
    "    top_5 = sorted(recommendations, key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "    # Add names\n",
    "    result = [{\n",
    "        \"business_id\": biz_id,\n",
    "        \"name\": business_id_to_name.get(biz_id, \"Unknown\"),\n",
    "        \"predicted_score\": round(score, 4)\n",
    "    } for biz_id, score in top_5]\n",
    "\n",
    "    return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544f8bc9-9f8d-4a64-8e9b-85f9119d83f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "mem = psutil.virtual_memory()\n",
    "print(f\"Used: {mem.used / 1e9:.2f} GB / Total: {mem.total / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd9531-e86f-4e30-b6a1-08322380c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_reviews.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddc0970-2c12-4fed-81e2-de6f53517659",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_top_5(\"ptDybsokuV3T_E7phLR28w\")  # Replace with real user_id from CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3c7a98-fc44-4c41-91bc-9bf84d487d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall tensorflow -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce8d0e-16fa-4395-8718-cd8466b954be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f973b8a-d1d4-43e5-b941-ec7e402c8ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7bf07b-487d-4a25-a86f-3aaded686f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e8083-9dc0-4734-b948-7897203b206f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c816f3-721f-4fab-b1d1-26f7bc5484ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load for the first time to set up files\n",
    "f.json_2_parquet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b147bc6-baf6-46a5-9fed-37031a9fc63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Set the correct network IP if necessary\n",
    "os.environ[\"SPARK_LOCAL_IP\"] = \"192.168.5.29\"  # or \"192.168.5.29\" if explicitly needed\n",
    "\n",
    "# Build Spark session WITHOUT RAPIDS\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkNoGPU\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to reduce verbosity\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(\"Spark session created!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffda3922-7c60-4c6e-bb8e-6265502c09c0",
   "metadata": {},
   "source": [
    "#### 2. Import JSON Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce56855-9e94-4b0e-936a-c0928c327f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load each Parquet file into a Spark DataFrame\n",
    "business_df = spark.read.parquet(os.path.join(parquet_dir, 'business.parquet')).sample(False, 0.1, seed=42)\n",
    "# review_df   = spark.read.parquet(os.path.join(parquet_dir, 'review.parquet')).sample(False, 0.1, seed=42)\n",
    "# checkin_df  = spark.read.parquet(os.path.join(parquet_dir, 'checkin.parquet')).sample(False, 0.1, seed=42)\n",
    "# tip_df      = spark.read.parquet(os.path.join(parquet_dir, 'tip.parquet')).sample(False, 0.1, seed=42)\n",
    "# user_df     = spark.read.parquet(os.path.join(parquet_dir, 'user.parquet')).sample(False, 0.1, seed=42)\n",
    "\n",
    "# Show a sample from one DataFrame\n",
    "business_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e56d5f-93bf-46ab-928a-d946c0912f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ylpenv)",
   "language": "python",
   "name": "ylpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
